# 0005.ai-function-calls

## Background

The AI chat assistant needs structured ways to interact with notebook cells beyond natural language. Function calls provide deterministic, auditable actions for reading and modifying code cells.

## User Story

> **As a** user chatting with the AI assistant  
> **I want** the AI to directly read and modify my notebook cells  
> **So that** I can get help without manual copy-pasting of code.

## Acceptance Criteria

1. AI can call `listCells()` to get a snapshot of all cells with ID, type, text, status, and output.
   - Returns `[{ id, type, text, status, output: ['output lines'] }]`.
2. AI can call `updateCell(id, text)` to replace cell contents.
   - Returns `{ success: true }` on success (may include an optional `message`).
3. Function calls render in the conversation as dedicated UI elements with clear status accents (icon/text color or badge), not mixed into plain text.
4. Status indicators mapping: blue (in-progress), gray (success), red (failure), orange (cancelled).
5. Each function lives in its own file under `src/ai-functions/` with a named export for the function and any Zod schemas/types.
6. Zod schemas are used for parameter validation. Schemas can be exported from `src/ai-functions/*` and/or defined inline in `tools.inputSchema`, but they MUST match.
7. Frontend-only integration: use a custom `ChatTransport` passed to `useChat` (no `/api/chat` backend route). Tools are provided via the AI SDK `tools` option; no `onToolCall` or manual `addToolResult()` is required.
8. Render tool call parts from `message.parts` exactly once, before assistant text for the same message.

## Technical Notes

- **Tools and validation**
  - Define tools via the AI SDK `tools` option: `{ [toolName]: { description, inputSchema: z.object(...), execute } }`.
  - Use Zod for `inputSchema`. Validate again inside `execute` if needed (`schema.parse(input)`), then call the function from `src/ai-functions/*`.
  - Keep function code and Zod schemas in `src/ai-functions/` (e.g., `listCellsParameters`, `updateCellParameters`). Inline schemas in `tools.inputSchema` are acceptable if they remain source-of-truth-consistent.

- **Vite frontend-only transport (no backend)**
  - Provide a custom `ChatTransport` to `useChat` that calls `streamText()` on the client with `{ model, system, messages, tools, toolChoice: 'auto' }`.
  - Return the AI SDK `toUIMessageStream()` when available; otherwise, synthesize a UI message stream (fallback).
  - Implement `reconnectToStream()` as a no-op. Do not rely on `/api/chat`.

- **useChat integration**
  - Pass the custom `transport` to `useChat({ transport })`. No `onToolCall` or manual `addToolResult()` is necessary when using AI SDK tools with client-side transport.
  - Supply the model/provider using a client API key (e.g., from settings/storage) or a Vite `VITE_*` env var.

- **UI rendering**
  - CRITICAL: render `message.parts`, not `message.content`.
  - Use `isToolOrDynamicToolUIPart` and `getToolOrDynamicToolName` to detect and render tool parts. Render tool parts before assistant text in the same message.
  - Prefer an expandable UI for tool details (function name, arguments, result), with status colors matching the acceptance criteria.

- **Error handling**
  - Show error status and details if a tool throws or the part indicates an error state.
  - Ensure graceful failure and clear user feedback.

## Vite frontend-only integration (outline + reference)

When building with Vite and no backend, use a custom client transport that runs inference in-browser. High-level outline:

1. Implement `createClientChatTransport(options)` that:
   - Resolves a client API key and model/provider.
   - Converts UI messages to model messages.
   - Calls `streamText({ model, system, messages, tools })`.
   - Returns `toUIMessageStream()` if available, else a synthesized UI message stream.
   - Defines a no-op `reconnectToStream`.
2. In `useAiChat`, build the `tools` map with Zod `inputSchema` and `execute` that calls `src/ai-functions/*`.
3. Create the transport with `{ apiKeyProvider, model, systemPrompt, tools }` and pass it to `useChat({ transport })`.
4. Render messages from `message.parts`, showing tool call parts (with status) before assistant text.
5. Store the API key in client storage or use a Vite `VITE_*` env var.

Reference: AI SDK + Vite (no backend) demo, which uses a custom transport and client-side `streamText()` to avoid `/api/chat`: [ai-sdk-vite-demo](https://github.com/The-Best-Codes/ai-sdk-vite-demo).

## Out of Scope

- Cancel button for function calls
- Parallel function execution (sequential only)

## Potential Pitfalls

- **Schema mismatch**: Must use Zod schemas, not JSON schemas
- **Parameter validation**: Always validate with Zod before execution

## Definition of Done

- All acceptance criteria are met
- Unit tests for function implementations
- Lint & type-check succeed
- Function calls work with correct status indicators
- No duplication in conversation balloons
- list cells, change the value of a cell, list cells again, make sure list cell calls return different values
