# 0006.AI_CHAT.md

## User Story

As a notebook user I want to chat with an AI assistant directly above each code cell so that I can ask questions, get explanations, and receive guidance without leaving the page.

## Acceptance Criteria

### Layout

- [ ] A chat history panel is positioned directly above the code cell.
- [ ] An input area (multi-line textarea) and a “Send” button sit directly below the history panel and above the code cell.
- [ ] Messages appear in the history in chronological order (oldest at top, newest at bottom).
- [ ] The history panel auto-scrolls to the newest message when a message is added.

### Behaviour

- [ ] Typing in the textarea and pressing “Send” (or ⌘/Ctrl + Enter) submits the message.
- [ ] The user’s message appears in the history immediately with a “sending…” state.
- [ ] The message is sent to `/api/chat`; once the AI replies the placeholder is replaced by the full response.
- [ ] The conversation is preserved for the duration of the page session, allowing back-and-forth dialogue.

### Backend / API

- [ ] A Next.js route handler is created at `app/api/chat/route.ts`.
- [ ] It uses the **Vercel AI SDK** to call the `gemini-2.5-flash` model.
- [ ] The model API key is read from the environment variable `GEMINI_API_KEY`.
- [ ] A system prompt constant exported from a TypeScript module (e.g. `prompts/system-prompt.ts`) is passed to every request (do NOT read from the filesystem at runtime).
- [ ] The endpoint streams the assistant’s reply so the UI can render partial tokens.
- [ ] Errors (missing key, rate limit, network, SDK failure) are returned as `500` JSON with a safe message.

### Technical

- [ ] Install and configure `vercel/ai` SDK (use `createGoogleGenerativeAI` factory + `streamText`).
- [ ] Define a shared TypeScript type `ChatMessage` with `{ role: 'user' | 'assistant'; content: string }`.
- [ ] Keep the conversation array on the client and send it with each request.
- [ ] Enter (⏎) sends; Shift/Ctrl/⌘ + Enter inserts a newline.
- [ ] No interaction with `CodeCell` execution engine in this user story.

### UI / UX

- [ ] Follow existing styling (Tailwind) and typography.
- [ ] Differentiate user vs. assistant messages with alignment or colour.
- [ ] Show a loading spinner while the assistant is thinking.
- [ ] Ensure the component is responsive (≥320 px).
- Pressing enter send a message, shift/cmd/ctrl+enter adds new line

### Definition of Done

1. User sees the chat interface above every code cell.
2. Messages are exchanged with the AI and the thread persists while the page is open.
3. The correct model (`gemini-2.5-flash`) is called via the Vercel AI SDK.
4. All acceptance criteria are met and tests / lint pass.
